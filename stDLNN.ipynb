{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2734dab4",
   "metadata": {},
   "source": [
    "# Parallel non-Cartesian Spatial-Temporal Dictionary Learning Neural Networks (stDLNN) for Accelerating 4D-MRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca385e",
   "metadata": {},
   "source": [
    "**Author:** Zhijun Wang, Huajun She  \n",
    "**Affiliation:** Shanghai Jiao Tong University  \n",
    "**Email:** wzj@mriee.com   \n",
    "**Date:** 2022/10/2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded0700",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch #1.8\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchkbnufft as tkbn #1.1.0 \n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.checkpoint import checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad002b48",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_I = 8\n",
    "patch_1 = [2, 3, 3, 3] # p_a, p_x, p_y, p_t\n",
    "spars_1 = [2, 3, 3, 3]\n",
    "H_L_1   = [128, 64, 32]\n",
    "N_I_1   = 3\n",
    "patch_list  = [patch_1 for i in range(M_I)]\n",
    "sparse_list = [spars_1 for i in range(M_I)]\n",
    "H_L_list    = [  H_L_1 for i in range(M_I)]\n",
    "N_I_list    = [  N_I_1 for i in range(M_I)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d27e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 25 \n",
    "alpha = 0.56\n",
    "b = 1 #batch size\n",
    "lr = 0.001\n",
    "num_epoch = 200\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f938ede2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f43ff36",
   "metadata": {},
   "source": [
    "### CEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771f799",
   "metadata": {},
   "source": [
    "Coefficient Estimation Module  \n",
    "\n",
    "x.shape = $ (b,l_a, l_b,p_1 \\times p_2  \\times p_3  \\times p_4) $  \n",
    "L_list : List of units in each layer  \n",
    "lam.shape = $ (b,l_a, l_b,1) $    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c24b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEM(nn.Module):\n",
    "    def __init__(self, L_list):\n",
    "        super().__init__()\n",
    "        self.actf = nn.ReLU(inplace = True)\n",
    "        Ls = []\n",
    "        for i in range(len(L_list)-1):\n",
    "            Ls.append(nn.Linear(L_list[i], L_list[i+1], bias=True))\n",
    "        self.Ls = nn.ModuleList(Ls)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for linear in self.Ls[:-1]:\n",
    "            x = self.actf(linear(x))\n",
    "        lam = self.Ls[-1](x)  \n",
    "        return lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1635a615",
   "metadata": {},
   "source": [
    "### PDM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd33882",
   "metadata": {},
   "source": [
    "Patch De-aliasing Module  \n",
    "  \n",
    "x.shape = $ (b, l_a, l_b,p_1 \\times p_2  \\times p_3  \\times p_4) $  \n",
    "lam.shape = $ (b, l_a, l_b, 1) $  \n",
    "psi.shape = $ (b, l_a, l_b, p_1 \\times p_2  \\times p_3  \\times p_4) $    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f72f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dict4 import Dict_4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b84b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_thresh(x, l):\n",
    "    return torch.sign(x) * (torch.abs(x) - l).clamp(min=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDM(nn.Module):\n",
    "    def __init__(self, N_I, patch_size, sparse_size):\n",
    "        super().__init__()\n",
    "        self.N_I = N_I \n",
    "        \n",
    "        Dict = Dict_4D(patch_size,sparse_size)\n",
    "        Dict = torch.from_numpy(Dict).float()\n",
    "        ps, nd = Dict.shape\n",
    "        self.Dict = nn.Parameter(Dict)\n",
    "        \n",
    "        Diag = torch.eye(nd)\n",
    "        self.Diag = nn.Parameter(Diag, requires_grad=False)\n",
    "        \n",
    "        zeta = 1 / np.linalg.norm(Dict, ord=2) ** 2\n",
    "        zeta = torch.FloatTensor((zeta / 2,))\n",
    "        self.zeta = nn.Parameter(zeta)       \n",
    "       \n",
    "\n",
    "    def forward(self, x, lam):\n",
    "        S = self.Diag - 2 * self.zeta * self.Dict.T.mm(self.Dict)\n",
    "        t = 2 * self.zeta * x.matmul(self.Dict)\n",
    "        theta = lam * self.zeta\n",
    "        g = soft_thresh(t, theta)\n",
    "        for n in range(self.N_I):\n",
    "            g = soft_thresh(g.matmul(S) + t, theta)\n",
    "        psi = g.matmul(self.Dict.T)\n",
    "        return psi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc81e13",
   "metadata": {},
   "source": [
    "### DN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35013f8b",
   "metadata": {},
   "source": [
    "De-aliasing Network  \n",
    "  \n",
    "x.shape = $ (b, N_a, N_x, N_y, N_t) $  \n",
    "z.shape = $ (b, N_a, N_x, N_y, N_t) $  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768df2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fold4 import unFold, Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DN(nn.Module):\n",
    "    def __init__(self, patch_size, sparse_size, H_L, N_I):\n",
    "\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.cem = CEM([np.prod(patch_size)]+H_L+[1])\n",
    "        self.pdm = PDM(N_I, patch_size, sparse_size)\n",
    "        q = torch.normal(mean=1.0, std=1.0 / 10 * torch.ones(np.prod(patch_size)))\n",
    "        self.q = nn.Parameter(q)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        output_size = x.shape\n",
    "        \n",
    "        Rx = unFold(x, self.patch_size) \n",
    "        lam = self.cem(Rx)\n",
    "        psi = self.pdm(Rx, lam)\n",
    "        psi *= self.q\n",
    "\n",
    "        one = torch.ones_like(psi)\n",
    "        one *= self.q\n",
    "        \n",
    "        z  =  Fold(psi, output_size, kernel_size=self.patch_size)\n",
    "        z /=  Fold(one, output_size, kernel_size=self.patch_size)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f096796",
   "metadata": {},
   "source": [
    "### DC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed51d605",
   "metadata": {},
   "source": [
    "parallel non-Cartesian Data Consistency  \n",
    "  \n",
    "x.shape = $ (b, N_a, N_x, N_y, N_t) $  \n",
    "x0.shape = $ (b, N_a, N_x, N_y, N_t) $  \n",
    "smap.shape =  $ (1, N_c, N_x, N_y) $   \n",
    "kern:  the filter responses taking into account Toeplitz embedding   \n",
    "xn.shape = $ (b, N_a, N_x, N_y, N_t) $  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5242dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.toep_ob = tkbn.ToepNufft()\n",
    "        \n",
    "    def multi_teop(self,z,smap,kerns):\n",
    "        outputs = []\n",
    "        for i in range(len(kerns)):\n",
    "            o = self.toep_ob(z[:,i:i+1,...], kerns[i], smaps=smap)\n",
    "            outputs.append(o)\n",
    "        return torch.cat(outputs,axis=1)    \n",
    "\n",
    "    def forward(self, z, x0, smap, kern, alpha):\n",
    "        z = z.permute(( 0, 4, 1, 2, 3)).contiguous()\n",
    "        x0 = x0.permute((0, 4, 1, 2, 3)).contiguous()\n",
    "        z = z[:,:,0,...] + z[:,:,1,...]*1j\n",
    "        x0 = x0[:,:,0,...] + x0[:,:,1,...]*1j\n",
    "        toep = self.multi_teop(z,smap,kern) \n",
    "        xn = z - alpha * (toep - x0)\n",
    "        xn = torch.stack([torch.real(xn),torch.imag(xn)],axis=2)\n",
    "        xn = xn.permute((0, 2, 3, 4, 1))\n",
    "        return xn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c18d0b8",
   "metadata": {},
   "source": [
    "### stDLNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4359ff",
   "metadata": {},
   "source": [
    "Parallel non-Cartesian Spatial-Temporal Dictionary Learning Neural Networks\n",
    "  \n",
    "x.shape = $ (b, N_a, N_x, N_y, N_t) $  \n",
    "smap.shape =  $ (1, N_c, N_x, N_y) $   \n",
    "kern: the filter responses taking into account Toeplitz embedding   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a292f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stDLNN(nn.Module):\n",
    "\n",
    "    def __init__(self, device, M_I, patch_list, sparse_list, H_L_list, N_I_list, init_alpha):\n",
    "        super().__init__()\n",
    "        self.M_I = M_I\n",
    "        \n",
    "        DNs = []  \n",
    "        for i in range(self.M_I):\n",
    "            DNs.append( DN(patch_size = patch_list[i], sparse_size = sparse_list[i],\n",
    "                           H_L = H_L_list[i], N_I = N_I_list[i]) )\n",
    "        self.DNs = nn.ModuleList(DNs)\n",
    "        self.dc  = DC()\n",
    "        self.alpha = nn.Parameter(torch.FloatTensor([init_alpha]))\n",
    "    \n",
    "    \n",
    "    def forward(self, x_und, smap, kern):\n",
    "        x = x_und\n",
    "        x.requires_grad_()\n",
    "        \n",
    "        for i in range(self.M_I):\n",
    "            x = checkpoint(self.DNs[i],x) #gradient checkpointing\n",
    "            x = self.dc(x, x_und, smap, kern, self.alpha)\n",
    "\n",
    "        return x    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171aaaa4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a567777",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdlnn = stDLNN(device, M_I, patch_list, sparse_list, H_L_list, N_I_list, alpha)\n",
    "stdlnn = stdlnn.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(stdlnn.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6d58f",
   "metadata": {},
   "source": [
    "im_u_set: training set (undersampled)  \n",
    "gnd_set:  training set (ground truth)  \n",
    "smap_set: sensitivity maps of training set   \n",
    "kern: the filter responses calculated by [tkbn.calc_toeplitz_kernel](https://torchkbnufft.readthedocs.io/en/stable/generated/torchkbnufft.calc_toeplitz_kernel.html) (weights: density compensation for radial trajectory and acceleration rate)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2569338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "\n",
    "    for im_u, gnd, smap in zip(im_u_set, gnd_set, smap_set): \n",
    "        optimizer.zero_grad()\n",
    "        rec = stdlnn(im_u, smap, kern)\n",
    "        loss = criterion(rec, gnd)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(stdlnn.parameters(), 1e-4)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_err += loss.item()\n",
    "        train_batches += 1\n",
    "        \n",
    "    return train_err / train_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d627bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
